Path: news.gmane.org!not-for-mail
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Newsgroups: gmane.linux.kernel,gmane.linux.kernel.stable
Subject: [ 20/40] mm: zone_reclaim: make isolate_lru_page() filter-aware
Date: Thu, 26 Jul 2012 14:29:38 -0700
Lines: 107
Approved: news@gmane.org
Message-ID: <20120726211412.942842840@linuxfoundation.org>
References: <20120726211424.GA7709@kroah.com>
 <20120726211411.164006056@linuxfoundation.org>
NNTP-Posting-Host: plane.gmane.org
X-Trace: dough.gmane.org 1343338279 9951 80.91.229.3 (26 Jul 2012 21:31:19 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Thu, 26 Jul 2012 21:31:19 +0000 (UTC)
Cc: Greg KH <gregkh@linuxfoundation.org>,
	torvalds@linux-foundation.org, akpm@linux-foundation.org,
	alan@lxorguk.ukuu.org.uk, Minchan Kim <minchan.kim@gmail.com>,
	Johannes Weiner <hannes@cmpxchg.org>,
	KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>,
	KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>,
	Michal Hocko <mhocko@suse.cz>, Mel Gorman <mgorman@suse.de>,
	Rik van Riel <riel@redhat.com>,
	Andrea Arcangeli <aarcange@redhat.com>
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org
Original-X-From: linux-kernel-owner@vger.kernel.org Thu Jul 26 23:31:16 2012
Return-path: <linux-kernel-owner@vger.kernel.org>
Envelope-to: glk-linux-kernel-3@plane.gmane.org
Original-Received: from vger.kernel.org ([209.132.180.67])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <linux-kernel-owner@vger.kernel.org>)
	id 1SuVeJ-0005gC-PS
	for glk-linux-kernel-3@plane.gmane.org; Thu, 26 Jul 2012 23:31:12 +0200
Original-Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753488Ab2GZVbI (ORCPT <rfc822;glk-linux-kernel-3@m.gmane.org>);
	Thu, 26 Jul 2012 17:31:08 -0400
Original-Received: from mail-yx0-f174.google.com ([209.85.213.174]:58435 "EHLO
	mail-yx0-f174.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753474Ab2GZVbC (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Thu, 26 Jul 2012 17:31:02 -0400
Original-Received: by mail-yx0-f174.google.com with SMTP id l2so2513141yen.19
        for <linux-kernel@vger.kernel.org>; Thu, 26 Jul 2012 14:31:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20120113;
        h=from:to:cc:subject:date:message-id:x-mailer:in-reply-to:references
         :user-agent:x-gm-message-state;
        bh=Hv2YbKxnVJlhQt7GMCWKhtfPKnefstWsHSnJApG1LTA=;
        b=HU+M6XWFS3w3EyMVkyFkssWvKTUu+e9dBx5UpoXYrd3q4NV2BuQ7jY5xLcyi6FKI7N
         Xzm26tPy9kxQx4vQsCluDQ3z77zdyY2mSEIWj0JFzM8bypaV1WVMDj116qYl0vLddHJT
         z23Nsl8tTa0j7vi64IGJ43fWRsrZkW9G85PTP5S2rK46hAIDINr3IirHKVK+zkUtcF+R
         g6Czc3IOPZGI98t0kKIQPPh5Lp7kdlMo05Uwsh2gVus2qyfexh4XHlXYn5wJLdPFpzTw
         98EaTMAzMloLfNLQPehmXiiHvbYEyzcTivrjYIWY/t6Do2NAj4LhQDLjG4xsymZ0ZKxk
         fOyA==
Original-Received: by 10.66.79.40 with SMTP id g8mr541372pax.27.1343338261828;
        Thu, 26 Jul 2012 14:31:01 -0700 (PDT)
Original-Received: from localhost (c-67-168-183-230.hsd1.wa.comcast.net. [67.168.183.230])
        by mx.google.com with ESMTPS id pf8sm431929pbc.44.2012.07.26.14.30.59
        (version=TLSv1/SSLv3 cipher=OTHER);
        Thu, 26 Jul 2012 14:31:00 -0700 (PDT)
X-Mailer: git-send-email 1.7.10.1.362.g242cab3
In-Reply-To: <20120726211411.164006056@linuxfoundation.org>
User-Agent: quilt/0.60-20.4
X-Gm-Message-State: ALoCoQk85l4gZH/6Xec9e7PcxK9KbJJ+bGnFaq+c67CFap/aLpqDYdIVL1hSH2GIToqMUnEH6PvR
Original-Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
Xref: news.gmane.org gmane.linux.kernel:1333931 gmane.linux.kernel.stable:28869
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1333931>

From: Greg KH <gregkh@linuxfoundation.org>

3.0-stable review patch.  If anyone has any objections, please let me know.

------------------

From: Minchan Kim <minchan.kim@gmail.com>

commit f80c0673610e36ae29d63e3297175e22f70dde5f upstream.

Stable note: Not tracked in Bugzilla. THP and compaction disrupt the LRU list
	leading to poor reclaim decisions which has a variable
	performance impact.

In __zone_reclaim case, we don't want to shrink mapped page.  Nonetheless,
we have isolated mapped page and re-add it into LRU's head.  It's
unnecessary CPU overhead and makes LRU churning.

Of course, when we isolate the page, the page might be mapped but when we
try to migrate the page, the page would be not mapped.  So it could be
migrated.  But race is rare and although it happens, it's no big deal.

Signed-off-by: Minchan Kim <minchan.kim@gmail.com>
Acked-by: Johannes Weiner <hannes@cmpxchg.org>
Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Reviewed-by: Michal Hocko <mhocko@suse.cz>
Cc: Mel Gorman <mgorman@suse.de>
Cc: Rik van Riel <riel@redhat.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

---
 include/linux/mmzone.h |    2 ++
 mm/vmscan.c            |   20 ++++++++++++++++++--
 2 files changed, 20 insertions(+), 2 deletions(-)

--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -164,6 +164,8 @@ static inline int is_unevictable_lru(enu
 #define ISOLATE_ACTIVE		((__force isolate_mode_t)0x2)
 /* Isolate clean file */
 #define ISOLATE_CLEAN		((__force isolate_mode_t)0x4)
+/* Isolate unmapped file */
+#define ISOLATE_UNMAPPED	((__force isolate_mode_t)0x8)
 
 /* LRU Isolation modes. */
 typedef unsigned __bitwise__ isolate_mode_t;
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -1048,6 +1048,9 @@ int __isolate_lru_page(struct page *page
 	if ((mode & ISOLATE_CLEAN) && (PageDirty(page) || PageWriteback(page)))
 		return ret;
 
+	if ((mode & ISOLATE_UNMAPPED) && page_mapped(page))
+		return ret;
+
 	if (likely(get_page_unless_zero(page))) {
 		/*
 		 * Be careful not to clear PageLRU until after we're
@@ -1471,6 +1474,12 @@ shrink_inactive_list(unsigned long nr_to
 		reclaim_mode |= ISOLATE_ACTIVE;
 
 	lru_add_drain();
+
+	if (!sc->may_unmap)
+		reclaim_mode |= ISOLATE_UNMAPPED;
+	if (!sc->may_writepage)
+		reclaim_mode |= ISOLATE_CLEAN;
+
 	spin_lock_irq(&zone->lru_lock);
 
 	if (scanning_global_lru(sc)) {
@@ -1588,19 +1597,26 @@ static void shrink_active_list(unsigned
 	struct page *page;
 	struct zone_reclaim_stat *reclaim_stat = get_reclaim_stat(zone, sc);
 	unsigned long nr_rotated = 0;
+	isolate_mode_t reclaim_mode = ISOLATE_ACTIVE;
 
 	lru_add_drain();
+
+	if (!sc->may_unmap)
+		reclaim_mode |= ISOLATE_UNMAPPED;
+	if (!sc->may_writepage)
+		reclaim_mode |= ISOLATE_CLEAN;
+
 	spin_lock_irq(&zone->lru_lock);
 	if (scanning_global_lru(sc)) {
 		nr_taken = isolate_pages_global(nr_pages, &l_hold,
 						&pgscanned, sc->order,
-						ISOLATE_ACTIVE, zone,
+						reclaim_mode, zone,
 						1, file);
 		zone->pages_scanned += pgscanned;
 	} else {
 		nr_taken = mem_cgroup_isolate_pages(nr_pages, &l_hold,
 						&pgscanned, sc->order,
-						ISOLATE_ACTIVE, zone,
+						reclaim_mode, zone,
 						sc->mem_cgroup, 1, file);
 		/*
 		 * mem_cgroup_isolate_pages() keeps track of


