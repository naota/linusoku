Path: news.gmane.org!not-for-mail
From: Peter Zijlstra <peterz@infradead.org>
Newsgroups: gmane.linux.kernel
Subject: Re: [PATCHSET] workqueue: reimplement CPU hotplug to keep idle
 workers
Date: Fri, 20 Jul 2012 19:19:27 +0200
Lines: 49
Approved: news@gmane.org
Message-ID: <1342804767.2583.40.camel@twins>
References: <1342545149-3515-1-git-send-email-tj@kernel.org>
	 <1342802391.2583.11.camel@twins> <20120720165213.GD32763@google.com>
	 <1342803700.2583.29.camel@twins> <20120720170802.GF32763@google.com>
NNTP-Posting-Host: plane.gmane.org
Mime-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7BIT
X-Trace: dough.gmane.org 1342804788 31152 80.91.229.3 (20 Jul 2012 17:19:48 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Fri, 20 Jul 2012 17:19:48 +0000 (UTC)
Cc: linux-kernel@vger.kernel.org, torvalds@linux-foundation.org,
	tglx@linutronix.de, linux-pm@vger.kernel.org
To: Tejun Heo <tj@kernel.org>
Original-X-From: linux-kernel-owner@vger.kernel.org Fri Jul 20 19:19:47 2012
Return-path: <linux-kernel-owner@vger.kernel.org>
Envelope-to: glk-linux-kernel-3@plane.gmane.org
Original-Received: from vger.kernel.org ([209.132.180.67])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <linux-kernel-owner@vger.kernel.org>)
	id 1SsGrf-0006a1-QV
	for glk-linux-kernel-3@plane.gmane.org; Fri, 20 Jul 2012 19:19:44 +0200
Original-Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753405Ab2GTRTg (ORCPT <rfc822;glk-linux-kernel-3@m.gmane.org>);
	Fri, 20 Jul 2012 13:19:36 -0400
Original-Received: from casper.infradead.org ([85.118.1.10]:35362 "EHLO
	casper.infradead.org" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752793Ab2GTRTd convert rfc822-to-8bit (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Fri, 20 Jul 2012 13:19:33 -0400
Original-Received: from dhcp-089-099-019-018.chello.nl ([89.99.19.18] helo=twins)
	by casper.infradead.org with esmtpsa (Exim 4.76 #1 (Red Hat Linux))
	id 1SsGrQ-0003MZ-42; Fri, 20 Jul 2012 17:19:28 +0000
Original-Received: by twins (Postfix, from userid 1000)
	id 69754800514C; Fri, 20 Jul 2012 19:19:27 +0200 (CEST)
In-Reply-To: <20120720170802.GF32763@google.com>
X-Mailer: Evolution 3.2.2- 
Original-Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
Xref: news.gmane.org gmane.linux.kernel:1330963
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1330963>

On Fri, 2012-07-20 at 10:08 -0700, Tejun Heo wrote:
> Hello, Peter.
> 
> On Fri, Jul 20, 2012 at 07:01:40PM +0200, Peter Zijlstra wrote:
> > On Fri, 2012-07-20 at 09:52 -0700, Tejun Heo wrote:
> > > Ooh, yeah, I agree.  That's next on the wq to-do list.  The problem is
> > > that queue_work() is implemented in terms of queue_work_on().  
> > 
> > But that's trivial to fix, both could use __queue_work() without too
> > much bother, right?
> 
> Hmmm?  Not really.  We need to keep count of the ones which reqested
> fixed binding - ie. the ones which explicitly used queue_work_on() -
> and then flush on wq CPU_DOWN.  Then, we need to audit the current
> users which are using queue_work{_on}() + explicit FLUSH on CPU_DOWN
> and convert them.

No, that's the wrong way about. Just add another WQ_flag, so you can
tell which work-queues want sane semantics and those mucking about for
laughs, say WQ_NON_AFFINE.

Then those with sane semantics (!WQ_NON_AFFINE) get an explicit flush on
DOWN and don't need to muck about with detaching and re-attaching etc..

> > > The assumption was that they should flush during CPU_DOWN but it
> > > probably will be much better to require users which need CPU affinity
> > > to always use queue_work_on() - instead of implicit local affinity
> > > from queue_work() - and flush them automatically from wq callback.
> > 
> > Right, and when you create this new mode, which you need to know to
> > flush on DOWN, you can simply put a BUG_ON in queue_work_on() when this
> > mode is set.
> 
> BUG_ON() on queue_work_on()?  Do you mean if the target CPU is down?
> If so, yeah, I'd probably go with WARN_ON_ONCE() but we should whine
> on it.

No, when you're trying to enqueue something to a specific cpu but don't
provide strict per-cpu semantics.

int queue_work_on(int cpu, struct workqueue_struct *wq, 
		  struct work_struct *work)
{
  WARN_ON(wq->flags & WQ_NON_AFFINE);

  ....
}


