Path: news.gmane.org!not-for-mail
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Newsgroups: gmane.linux.kernel,gmane.linux.kernel.stable
Subject: [ 20/41] mm: zone_reclaim: make isolate_lru_page() filter-aware
Date: Mon, 30 Jul 2012 10:31:19 -0700
Lines: 107
Approved: news@gmane.org
Message-ID: <20120730172902.893502791@linuxfoundation.org>
References: <20120730172901.306897424@linuxfoundation.org>
NNTP-Posting-Host: plane.gmane.org
X-Trace: dough.gmane.org 1343669986 27640 80.91.229.3 (30 Jul 2012 17:39:46 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Mon, 30 Jul 2012 17:39:46 +0000 (UTC)
Cc: Greg KH <gregkh@linuxfoundation.org>,
	torvalds@linux-foundation.org, akpm@linux-foundation.org,
	alan@lxorguk.ukuu.org.uk, Minchan Kim <minchan.kim@gmail.com>,
	Johannes Weiner <hannes@cmpxchg.org>,
	KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>,
	KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>,
	Michal Hocko <mhocko@suse.cz>, Mel Gorman <mgorman@suse.de>,
	Rik van Riel <riel@redhat.com>,
	Andrea Arcangeli <aarcange@redhat.com>
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org
Original-X-From: linux-kernel-owner@vger.kernel.org Mon Jul 30 19:39:44 2012
Return-path: <linux-kernel-owner@vger.kernel.org>
Envelope-to: glk-linux-kernel-3@plane.gmane.org
Original-Received: from vger.kernel.org ([209.132.180.67])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <linux-kernel-owner@vger.kernel.org>)
	id 1SvtwV-0006Ym-9C
	for glk-linux-kernel-3@plane.gmane.org; Mon, 30 Jul 2012 19:39:43 +0200
Original-Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755009Ab2G3Rjc (ORCPT <rfc822;glk-linux-kernel-3@m.gmane.org>);
	Mon, 30 Jul 2012 13:39:32 -0400
Original-Received: from mail-pb0-f46.google.com ([209.85.160.46]:38517 "EHLO
	mail-pb0-f46.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1754936Ab2G3RdB (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Mon, 30 Jul 2012 13:33:01 -0400
Original-Received: by mail-pb0-f46.google.com with SMTP id rp8so10147880pbb.19
        for <linux-kernel@vger.kernel.org>; Mon, 30 Jul 2012 10:33:01 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20120113;
        h=from:to:cc:subject:date:message-id:x-mailer:in-reply-to:references
         :user-agent:x-gm-message-state;
        bh=Hv2YbKxnVJlhQt7GMCWKhtfPKnefstWsHSnJApG1LTA=;
        b=JwZmT5Uz58qRUMZ6AwcDNlpRe32Dtib6tUylaDRGdKwIdXEFRgBi+YEpP+pAPOqmn4
         vNQmtkQNkQOg42X+NtYwr0MV/rfXswI9r9b25tkgYX7bWYZx3YoAATR9HtMHeaRcgpXO
         GEdrLPNSik51TbDINNDtWn/vwkRcG6eukhMSufyIT14AaLxGFkcqB3qCCF2hEaHuctwo
         qZSfOIw1B9ZlwH2EdUFFZ5FEtPkm0ygnmn5Mh8H4imytUSmmOOPdaZKf7dBEOds7C6Sg
         YwySpZRwZRU3KskGiLS2uBZXVoNTIF4z7M/0CpRRstwFxJ5O9iexHu8na1+58KhUF8Qo
         ShGQ==
Original-Received: by 10.68.197.70 with SMTP id is6mr36281818pbc.64.1343669581543;
        Mon, 30 Jul 2012 10:33:01 -0700 (PDT)
Original-Received: from localhost (c-67-168-183-230.hsd1.wa.comcast.net. [67.168.183.230])
        by mx.google.com with ESMTPS id pf8sm8293519pbc.44.2012.07.30.10.32.59
        (version=TLSv1/SSLv3 cipher=OTHER);
        Mon, 30 Jul 2012 10:33:00 -0700 (PDT)
X-Mailer: git-send-email 1.7.10.1.362.g242cab3
In-Reply-To: <20120730172901.306897424@linuxfoundation.org>
User-Agent: quilt/0.60-20.4
X-Gm-Message-State: ALoCoQkhSt4sB1S2VMof2Lq7k59zWhvD2pbGAvCcBEGTotG78sZO8kWHgrukQnTxlWSCjpsblTsG
Original-Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
Xref: news.gmane.org gmane.linux.kernel:1335226 gmane.linux.kernel.stable:28966
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1335226>

From: Greg KH <gregkh@linuxfoundation.org>

3.0-stable review patch.  If anyone has any objections, please let me know.

------------------

From: Minchan Kim <minchan.kim@gmail.com>

commit f80c0673610e36ae29d63e3297175e22f70dde5f upstream.

Stable note: Not tracked in Bugzilla. THP and compaction disrupt the LRU list
	leading to poor reclaim decisions which has a variable
	performance impact.

In __zone_reclaim case, we don't want to shrink mapped page.  Nonetheless,
we have isolated mapped page and re-add it into LRU's head.  It's
unnecessary CPU overhead and makes LRU churning.

Of course, when we isolate the page, the page might be mapped but when we
try to migrate the page, the page would be not mapped.  So it could be
migrated.  But race is rare and although it happens, it's no big deal.

Signed-off-by: Minchan Kim <minchan.kim@gmail.com>
Acked-by: Johannes Weiner <hannes@cmpxchg.org>
Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Reviewed-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Reviewed-by: Michal Hocko <mhocko@suse.cz>
Cc: Mel Gorman <mgorman@suse.de>
Cc: Rik van Riel <riel@redhat.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

---
 include/linux/mmzone.h |    2 ++
 mm/vmscan.c            |   20 ++++++++++++++++++--
 2 files changed, 20 insertions(+), 2 deletions(-)

--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -164,6 +164,8 @@ static inline int is_unevictable_lru(enu
 #define ISOLATE_ACTIVE		((__force isolate_mode_t)0x2)
 /* Isolate clean file */
 #define ISOLATE_CLEAN		((__force isolate_mode_t)0x4)
+/* Isolate unmapped file */
+#define ISOLATE_UNMAPPED	((__force isolate_mode_t)0x8)
 
 /* LRU Isolation modes. */
 typedef unsigned __bitwise__ isolate_mode_t;
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -1048,6 +1048,9 @@ int __isolate_lru_page(struct page *page
 	if ((mode & ISOLATE_CLEAN) && (PageDirty(page) || PageWriteback(page)))
 		return ret;
 
+	if ((mode & ISOLATE_UNMAPPED) && page_mapped(page))
+		return ret;
+
 	if (likely(get_page_unless_zero(page))) {
 		/*
 		 * Be careful not to clear PageLRU until after we're
@@ -1471,6 +1474,12 @@ shrink_inactive_list(unsigned long nr_to
 		reclaim_mode |= ISOLATE_ACTIVE;
 
 	lru_add_drain();
+
+	if (!sc->may_unmap)
+		reclaim_mode |= ISOLATE_UNMAPPED;
+	if (!sc->may_writepage)
+		reclaim_mode |= ISOLATE_CLEAN;
+
 	spin_lock_irq(&zone->lru_lock);
 
 	if (scanning_global_lru(sc)) {
@@ -1588,19 +1597,26 @@ static void shrink_active_list(unsigned
 	struct page *page;
 	struct zone_reclaim_stat *reclaim_stat = get_reclaim_stat(zone, sc);
 	unsigned long nr_rotated = 0;
+	isolate_mode_t reclaim_mode = ISOLATE_ACTIVE;
 
 	lru_add_drain();
+
+	if (!sc->may_unmap)
+		reclaim_mode |= ISOLATE_UNMAPPED;
+	if (!sc->may_writepage)
+		reclaim_mode |= ISOLATE_CLEAN;
+
 	spin_lock_irq(&zone->lru_lock);
 	if (scanning_global_lru(sc)) {
 		nr_taken = isolate_pages_global(nr_pages, &l_hold,
 						&pgscanned, sc->order,
-						ISOLATE_ACTIVE, zone,
+						reclaim_mode, zone,
 						1, file);
 		zone->pages_scanned += pgscanned;
 	} else {
 		nr_taken = mem_cgroup_isolate_pages(nr_pages, &l_hold,
 						&pgscanned, sc->order,
-						ISOLATE_ACTIVE, zone,
+						reclaim_mode, zone,
 						sc->mem_cgroup, 1, file);
 		/*
 		 * mem_cgroup_isolate_pages() keeps track of


