Path: news.gmane.org!not-for-mail
From: Mel Gorman <mgorman@suse.de>
Newsgroups: gmane.linux.kernel.mm,gmane.linux.kernel,gmane.linux.file-systems
Subject: [MMTests] dbench4 async on ext3
Date: Mon, 23 Jul 2012 22:21:46 +0100
Lines: 80
Approved: news@gmane.org
Message-ID: <20120723212146.GG9222@suse.de>
References: <20120620113252.GE4011@suse.de>
 <20120629111932.GA14154@suse.de>
NNTP-Posting-Host: plane.gmane.org
Mime-Version: 1.0
Content-Type: text/plain; charset=iso-8859-15
X-Trace: dough.gmane.org 1343078558 7423 80.91.229.3 (23 Jul 2012 21:22:38 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Mon, 23 Jul 2012 21:22:38 +0000 (UTC)
Cc: linux-kernel@vger.kernel.org, linux-fsdevel@vger.kernel.org
To: linux-mm@kvack.org
Original-X-From: owner-linux-mm@kvack.org Mon Jul 23 23:22:38 2012
Return-path: <owner-linux-mm@kvack.org>
Envelope-to: glkm-linux-mm-2@m.gmane.org
Original-Received: from kanga.kvack.org ([205.233.56.17])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <owner-linux-mm@kvack.org>)
	id 1StQ5L-0003P3-MU
	for glkm-linux-mm-2@m.gmane.org; Mon, 23 Jul 2012 23:22:35 +0200
Original-Received: by kanga.kvack.org (Postfix)
	id 0CEF66B005D; Mon, 23 Jul 2012 17:22:34 -0400 (EDT)
Delivered-To: linux-mm-outgoing@kvack.org
Original-Received: by kanga.kvack.org (Postfix, from userid 40)
	id EC6AB6B0062; Mon, 23 Jul 2012 17:22:33 -0400 (EDT)
X-Original-To: int-list-linux-mm@kvack.org
Delivered-To: int-list-linux-mm@kvack.org
Original-Received: by kanga.kvack.org (Postfix, from userid 63042)
	id B98AB6B0068; Mon, 23 Jul 2012 17:22:33 -0400 (EDT)
X-Original-To: linux-mm@kvack.org
Delivered-To: linux-mm@kvack.org
Original-Received: from psmtp.com (na3sys010amx192.postini.com [74.125.245.192])
	by kanga.kvack.org (Postfix) with SMTP id CCFE66B005D
	for <linux-mm@kvack.org>; Mon, 23 Jul 2012 17:22:32 -0400 (EDT)
Original-Received: from mx2.suse.de ([195.135.220.15]) (using TLSv1) by na3sys010amx192.postini.com ([74.125.244.10]) with SMTP;
	Mon, 23 Jul 2012 21:22:33 GMT
Original-Received: from relay1.suse.de (unknown [195.135.220.254])
	(using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx2.suse.de (Postfix) with ESMTP id 25EB5A3E14;
	Mon, 23 Jul 2012 23:22:31 +0200 (CEST)
Content-Disposition: inline
In-Reply-To: <20120629111932.GA14154@suse.de>
User-Agent: Mutt/1.5.21 (2010-09-15)
X-pstn-neptune: 0/0/0.00/0
X-pstn-levels: (S:99.90000/99.90000 CV:99.9000 FC:95.5390 LC:95.5390 R:95.9108 P:95.9108 M:97.0282 C:98.6951 )
X-pstn-dkim: 0 skipped:not-enabled
X-pstn-settings: 3 (1.0000:1.0000) s cv gt3 gt2 gt1 r p m c 
X-pstn-addresses: from <mgorman@suse.de> [db-null] 
X-Bogosity: Ham, tests=bogofilter, spamicity=0.000000, version=1.2.2
Original-Sender: owner-linux-mm@kvack.org
Precedence: bulk
X-Loop: owner-majordomo@kvack.org
List-ID: <linux-mm.kvack.org>
Xref: news.gmane.org gmane.linux.kernel.mm:82903 gmane.linux.kernel:1332004 gmane.linux.file-systems:66166
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1332004>

Configuration:	global-dhp__io-dbench4-async-ext3
Result: 	http://www.csn.ul.ie/~mel/postings/mmtests-20120424/global-dhp__io-dbench4-async-ext3
Benchmarks:	dbench4

Summary
=======

In general there was a massive drop in throughput after 3.0. Very broadly
speaking it looks like the Read operation got faster but at the cost of
a big regression in the Flush operation.

Benchmark notes
===============

mkfs was run on system startup. No attempt was made to age it. No
special mkfs or mount options were used.

dbench 4 was used. Tests ran for 180 seconds once warmed up. A varying
number of clients were used up to 64*NR_CPU. osync, sync-directory and
fsync were all off.

===========================================================
Machine:	arnold
Result:		http://www.csn.ul.ie/~mel/postings/mmtests-20120424/global-dhp__io-dbench4-async-ext3/arnold/comparison.html
Arch:		x86
CPUs:		1 socket, 2 threads
Model:		Pentium 4
Disk:		Single Rotary Disk
===========================================================

dbench4
-------

  Generally worse with a big drop in throughput after 3.0 for small number
  of clients. In some cases there is an improvement in latency for 3.0
  and later kernels but not always.

==========================================================
Machine:	hydra
Result:		http://www.csn.ul.ie/~mel/postings/mmtests-20120424/global-dhp__io-dbench4-async-ext3/hydra/comparison.html
Arch:		x86-64
CPUs:		1 socket, 4 threads
Model:		AMD Phenom II X4 940
Disk:		Single Rotary Disk
Status:		Ok
==========================================================

dbench4
-------
  Similar to arnold, big drop in throughput after 3.0 for small numbers
  of clients. Unlike arnold, this is matched by an improvement in latency
  so it may be the case that IO is more fair even if dbench complains
  about the latency. Very very broadly speaking, it looks like the read
  operation got a lot faster but flush got a lot slower.

==========================================================
Machine:	sandy
Result:		http://www.csn.ul.ie/~mel/postings/mmtests-20120424/global-dhp__io-dbench4-async-ext3/sandy/comparison.html
Arch:		x86-64
CPUs:		1 socket, 8 threads
Model:		Intel Core i7-2600
Disk:		Single Rotary Disk
Status:		
==========================================================

dbench4
-------
  Same story, big drop in throughput after 3.0 with flush again looking very
  expensive for 3.1 and later kernels. Latency figures are a mixed bag.

-- 
Mel Gorman
SUSE Labs

--
To unsubscribe, send a message with 'unsubscribe linux-mm' in
the body to majordomo@kvack.org.  For more info on Linux MM,
see: http://www.linux-mm.org/ .
Don't email: <a href=mailto:"dont@kvack.org"> email@kvack.org </a>

