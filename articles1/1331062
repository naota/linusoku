Path: news.gmane.org!not-for-mail
From: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
Newsgroups: gmane.linux.kernel,gmane.linux.kernel.stable
Subject: Re: [PATCH 1/9] workqueue: perform cpu down operations from low
 priority cpu_notifier()
Date: Fri, 20 Jul 2012 14:52:07 -0700
Lines: 129
Approved: news@gmane.org
Message-ID: <20120720215207.GA18841@linux.vnet.ibm.com>
References: <1342545149-3515-1-git-send-email-tj@kernel.org>
 <1342545149-3515-2-git-send-email-tj@kernel.org>
Reply-To: paulmck@linux.vnet.ibm.com
NNTP-Posting-Host: plane.gmane.org
Mime-Version: 1.0
Content-Type: text/plain; charset=us-ascii
X-Trace: dough.gmane.org 1342821154 27433 80.91.229.3 (20 Jul 2012 21:52:34 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Fri, 20 Jul 2012 21:52:34 +0000 (UTC)
Cc: linux-kernel@vger.kernel.org, torvalds@linux-foundation.org,
	peterz@infradead.org, tglx@linutronix.de, linux-pm@vger.kernel.org,
	stable@vger.kernel.org
To: Tejun Heo <tj@kernel.org>
Original-X-From: linux-kernel-owner@vger.kernel.org Fri Jul 20 23:52:32 2012
Return-path: <linux-kernel-owner@vger.kernel.org>
Envelope-to: glk-linux-kernel-3@plane.gmane.org
Original-Received: from vger.kernel.org ([209.132.180.67])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <linux-kernel-owner@vger.kernel.org>)
	id 1SsL7d-0001Ai-00
	for glk-linux-kernel-3@plane.gmane.org; Fri, 20 Jul 2012 23:52:29 +0200
Original-Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753422Ab2GTVwR (ORCPT <rfc822;glk-linux-kernel-3@m.gmane.org>);
	Fri, 20 Jul 2012 17:52:17 -0400
Original-Received: from e35.co.us.ibm.com ([32.97.110.153]:58623 "EHLO
	e35.co.us.ibm.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753196Ab2GTVwO (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Fri, 20 Jul 2012 17:52:14 -0400
Original-Received: from /spool/local
	by e35.co.us.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
	for <linux-kernel@vger.kernel.org> from <paulmck@linux.vnet.ibm.com>;
	Fri, 20 Jul 2012 15:52:13 -0600
Original-Received: from d03dlp02.boulder.ibm.com (9.17.202.178)
	by e35.co.us.ibm.com (192.168.1.135) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
	Fri, 20 Jul 2012 15:52:12 -0600
Original-Received: from d03relay03.boulder.ibm.com (d03relay03.boulder.ibm.com [9.17.195.228])
	by d03dlp02.boulder.ibm.com (Postfix) with ESMTP id 36ED83E40039;
	Fri, 20 Jul 2012 21:52:11 +0000 (WET)
Original-Received: from d03av01.boulder.ibm.com (d03av01.boulder.ibm.com [9.17.195.167])
	by d03relay03.boulder.ibm.com (8.13.8/8.13.8/NCO v10.0) with ESMTP id q6KLqBcF258066;
	Fri, 20 Jul 2012 15:52:11 -0600
Original-Received: from d03av01.boulder.ibm.com (loopback [127.0.0.1])
	by d03av01.boulder.ibm.com (8.14.4/8.13.1/NCO v10.0 AVout) with ESMTP id q6KLq98x010716;
	Fri, 20 Jul 2012 15:52:11 -0600
Original-Received: from paulmck-ThinkPad-W500 ([9.47.24.210])
	by d03av01.boulder.ibm.com (8.14.4/8.13.1/NCO v10.0 AVin) with ESMTP id q6KLq7lC010658;
	Fri, 20 Jul 2012 15:52:07 -0600
Original-Received: by paulmck-ThinkPad-W500 (Postfix, from userid 1000)
	id 5137EE4D7A; Fri, 20 Jul 2012 14:52:07 -0700 (PDT)
Content-Disposition: inline
In-Reply-To: <1342545149-3515-2-git-send-email-tj@kernel.org>
User-Agent: Mutt/1.5.21 (2010-09-15)
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 12072021-6148-0000-0000-000007D663C3
Original-Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
Xref: news.gmane.org gmane.linux.kernel:1331062 gmane.linux.kernel.stable:28602
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1331062>

On Tue, Jul 17, 2012 at 10:12:21AM -0700, Tejun Heo wrote:
> Currently, all workqueue cpu hotplug operations run off
> CPU_PRI_WORKQUEUE which is higher than normal notifiers.  This is to
> ensure that workqueue is up and running while bringing up a CPU before
> other notifiers try to use workqueue on the CPU.
> 
> Per-cpu workqueues are supposed to remain working and bound to the CPU
> for normal CPU_DOWN_PREPARE notifiers.  This holds mostly true even
> with workqueue offlining running with higher priority because
> workqueue CPU_DOWN_PREPARE only creates a bound trustee thread which
> runs the per-cpu workqueue without concurrency management without
> explicitly detaching the existing workers.
> 
> However, if the trustee needs to create new workers, it creates
> unbound workers which may wander off to other CPUs while
> CPU_DOWN_PREPARE notifiers are in progress.  Furthermore, if the CPU
> down is cancelled, the per-CPU workqueue may end up with workers which
> aren't bound to the CPU.
> 
> While reliably reproducible with a convoluted artificial test-case
> involving scheduling and flushing CPU burning work items from CPU down
> notifiers, this isn't very likely to happen in the wild, and, even
> when it happens, the effects are likely to be hidden by the following
> successful CPU down.
> 
> Fix it by using different priorities for up and down notifiers - high
> priority for up operations and low priority for down operations.

Cool!!!

This certainly provides another data point in favor of running down
notifiers in the opposite order from up notifiers.  ;-)

This series passes light rcutorture/hotplug testing, will be testing
it more.

							Thanx, Paul

> Workqueue cpu hotplug operations will soon go through further cleanup.
> 
> Signed-off-by: Tejun Heo <tj@kernel.org>
> Cc: stable@vger.kernel.org
> ---
>  include/linux/cpu.h |    5 +++--
>  kernel/workqueue.c  |   38 +++++++++++++++++++++++++++++++++++++-
>  2 files changed, 40 insertions(+), 3 deletions(-)
> 
> diff --git a/include/linux/cpu.h b/include/linux/cpu.h
> index 2e9b9eb..ce7a074 100644
> --- a/include/linux/cpu.h
> +++ b/include/linux/cpu.h
> @@ -73,8 +73,9 @@ enum {
>  	/* migration should happen before other stuff but after perf */
>  	CPU_PRI_PERF		= 20,
>  	CPU_PRI_MIGRATION	= 10,
> -	/* prepare workqueues for other notifiers */
> -	CPU_PRI_WORKQUEUE	= 5,
> +	/* bring up workqueues before normal notifiers and down after */
> +	CPU_PRI_WORKQUEUE_UP	= 5,
> +	CPU_PRI_WORKQUEUE_DOWN	= -5,
>  };
> 
>  #define CPU_ONLINE		0x0002 /* CPU (unsigned)v is up */
> diff --git a/kernel/workqueue.c b/kernel/workqueue.c
> index 4fa9e35..f59b7fd 100644
> --- a/kernel/workqueue.c
> +++ b/kernel/workqueue.c
> @@ -3644,6 +3644,41 @@ err_destroy:
>  	return NOTIFY_BAD;
>  }
> 
> +/*
> + * Workqueues should be brought up before normal priority CPU notifiers.
> + * This will be registered high priority CPU notifier.
> + */
> +static int __devinit workqueue_cpu_up_callback(struct notifier_block *nfb,
> +					       unsigned long action,
> +					       void *hcpu)
> +{
> +	switch (action & ~CPU_TASKS_FROZEN) {
> +	case CPU_UP_PREPARE:
> +	case CPU_UP_CANCELED:
> +	case CPU_DOWN_FAILED:
> +	case CPU_ONLINE:
> +		return workqueue_cpu_callback(nfb, action, hcpu);
> +	}
> +	return NOTIFY_OK;
> +}
> +
> +/*
> + * Workqueues should be brought down after normal priority CPU notifiers.
> + * This will be registered as low priority CPU notifier.
> + */
> +static int __devinit workqueue_cpu_down_callback(struct notifier_block *nfb,
> +						 unsigned long action,
> +						 void *hcpu)
> +{
> +	switch (action & ~CPU_TASKS_FROZEN) {
> +	case CPU_DOWN_PREPARE:
> +	case CPU_DYING:
> +	case CPU_POST_DEAD:
> +		return workqueue_cpu_callback(nfb, action, hcpu);
> +	}
> +	return NOTIFY_OK;
> +}
> +
>  #ifdef CONFIG_SMP
> 
>  struct work_for_cpu {
> @@ -3839,7 +3874,8 @@ static int __init init_workqueues(void)
>  	unsigned int cpu;
>  	int i;
> 
> -	cpu_notifier(workqueue_cpu_callback, CPU_PRI_WORKQUEUE);
> +	cpu_notifier(workqueue_cpu_up_callback, CPU_PRI_WORKQUEUE_UP);
> +	cpu_notifier(workqueue_cpu_down_callback, CPU_PRI_WORKQUEUE_DOWN);
> 
>  	/* initialize gcwqs */
>  	for_each_gcwq_cpu(cpu) {
> -- 
> 1.7.7.3
> 
> --
> To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
> Please read the FAQ at  http://www.tux.org/lkml/
> 

