Path: news.gmane.org!not-for-mail
From: Tejun Heo <tj@kernel.org>
Newsgroups: gmane.linux.kernel
Subject: [PATCH 06/15] workqueue: unify local CPU queueing handling
Date: Fri, 27 Jul 2012 16:54:59 -0700
Lines: 101
Approved: news@gmane.org
Message-ID: <1343433308-26614-7-git-send-email-tj@kernel.org>
References: <1343433308-26614-1-git-send-email-tj@kernel.org>
NNTP-Posting-Host: plane.gmane.org
X-Trace: dough.gmane.org 1343433504 22778 80.91.229.3 (27 Jul 2012 23:58:24 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Fri, 27 Jul 2012 23:58:24 +0000 (UTC)
Cc: torvalds@linux-foundation.org, akpm@linux-foundation.org,
	padovan@profusion.mobi, marcel@holtmann.org, peterz@infradead.org,
	mingo@redhat.com, davem@davemloft.net, dougthompson@xmission.com,
	ibm-acpi@hmh.eng.br, cbou@mail.ru, rui.zhang@intel.com,
	Tejun Heo <tj@kernel.org>
To: linux-kernel@vger.kernel.org
Original-X-From: linux-kernel-owner@vger.kernel.org Sat Jul 28 01:58:20 2012
Return-path: <linux-kernel-owner@vger.kernel.org>
Envelope-to: glk-linux-kernel-3@plane.gmane.org
Original-Received: from vger.kernel.org ([209.132.180.67])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <linux-kernel-owner@vger.kernel.org>)
	id 1SuuQF-00035X-M1
	for glk-linux-kernel-3@plane.gmane.org; Sat, 28 Jul 2012 01:58:19 +0200
Original-Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753025Ab2G0X6M (ORCPT <rfc822;glk-linux-kernel-3@m.gmane.org>);
	Fri, 27 Jul 2012 19:58:12 -0400
Original-Received: from mail-pb0-f46.google.com ([209.85.160.46]:47011 "EHLO
	mail-pb0-f46.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752673Ab2G0Xz3 (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Fri, 27 Jul 2012 19:55:29 -0400
Original-Received: by mail-pb0-f46.google.com with SMTP id rp8so5796097pbb.19
        for <linux-kernel@vger.kernel.org>; Fri, 27 Jul 2012 16:55:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=sender:from:to:cc:subject:date:message-id:x-mailer:in-reply-to
         :references;
        bh=NsqRdDqENRl0k6jQDJDJivQUHfM1siQNJoCy+e9KiHs=;
        b=tGUhSLaByygarSllSmfT6Ey62x9tqtqaWhbF0TTLVazUOnZXz0wAGpflUmsTncZqzk
         zDDyTjHAdlk5CMds3zUpPvpkkpcGez2nn1/QkLMpGIFlOYB8Z+NufASjzID03HhF+NNg
         i/xbgmVdKYLv5nctQUutnKbRnhA7g63dKHyjkF2EJF95oyDfoOigFNes+KruV0EwWAqI
         PgO7Anp/NJ+STK94b01yXkyojrPqhBeMwjJ72kFyDy8WElgBCR0Iqka/Bb5obzo6Bgnt
         oxTI7iZLeXYy5jCPfJGPjg0hjJ0Uz0wV3g/QO1OvyquN/Bif/qLpWAuSVYmNggE8g77t
         sk+Q==
Original-Received: by 10.68.235.236 with SMTP id up12mr17510231pbc.79.1343433328911;
        Fri, 27 Jul 2012 16:55:28 -0700 (PDT)
Original-Received: from wtj.mtv.corp.google.com (wtj.mtv.corp.google.com [172.18.110.84])
        by mx.google.com with ESMTPS id ph1sm2797326pbb.45.2012.07.27.16.55.26
        (version=TLSv1/SSLv3 cipher=OTHER);
        Fri, 27 Jul 2012 16:55:27 -0700 (PDT)
X-Mailer: git-send-email 1.7.7.3
In-Reply-To: <1343433308-26614-1-git-send-email-tj@kernel.org>
Original-Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
Xref: news.gmane.org gmane.linux.kernel:1334559
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1334559>

Queueing functions have been using different methods to determine the
local CPU.

* queue_work() superflously uses get/put_cpu() to acquire and hold the
  local CPU across queue_work_on().

* delayed_work_timer_fn() uses smp_processor_id().

* queue_delayed_work() calls queue_delayed_work_on() with -1 @cpu
  which is interpreted as the local CPU.

* flush_delayed_work[_sync]() were using raw_smp_processor_id().

* __queue_work() interprets %WORK_CPU_UNBOUND as local CPU if the
  target workqueue is bound one but nobody uses this.

This patch converts all functions to uniformly use %WORK_CPU_UNBOUND
to indicate local CPU and use the local binding feature of
__queue_work().  unlikely() is dropped from %WORK_CPU_UNBOUND handling
in __queue_work().

Signed-off-by: Tejun Heo <tj@kernel.org>
---
 kernel/workqueue.c |   19 +++++++------------
 1 files changed, 7 insertions(+), 12 deletions(-)

diff --git a/kernel/workqueue.c b/kernel/workqueue.c
index db8098b..4beb9bf 100644
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -1005,7 +1005,7 @@ static void __queue_work(unsigned int cpu, struct workqueue_struct *wq,
 	if (!(wq->flags & WQ_UNBOUND)) {
 		struct global_cwq *last_gcwq;
 
-		if (unlikely(cpu == WORK_CPU_UNBOUND))
+		if (cpu == WORK_CPU_UNBOUND)
 			cpu = raw_smp_processor_id();
 
 		/*
@@ -1103,12 +1103,7 @@ EXPORT_SYMBOL_GPL(queue_work_on);
  */
 bool queue_work(struct workqueue_struct *wq, struct work_struct *work)
 {
-	bool ret;
-
-	ret = queue_work_on(get_cpu(), wq, work);
-	put_cpu();
-
-	return ret;
+	return queue_work_on(WORK_CPU_UNBOUND, wq, work);
 }
 EXPORT_SYMBOL_GPL(queue_work);
 
@@ -1117,7 +1112,7 @@ void delayed_work_timer_fn(unsigned long __data)
 	struct delayed_work *dwork = (struct delayed_work *)__data;
 	struct cpu_workqueue_struct *cwq = get_work_cwq(&dwork->work);
 
-	__queue_work(smp_processor_id(), cwq->wq, &dwork->work);
+	__queue_work(WORK_CPU_UNBOUND, cwq->wq, &dwork->work);
 }
 EXPORT_SYMBOL_GPL(delayed_work_timer_fn);
 
@@ -1172,7 +1167,7 @@ bool queue_delayed_work_on(int cpu, struct workqueue_struct *wq,
 
 		timer->expires = jiffies + delay;
 
-		if (unlikely(cpu >= 0))
+		if (unlikely(cpu != WORK_CPU_UNBOUND))
 			add_timer_on(timer, cpu);
 		else
 			add_timer(timer);
@@ -1198,7 +1193,7 @@ bool queue_delayed_work(struct workqueue_struct *wq,
 	if (delay == 0)
 		return queue_work(wq, &dwork->work);
 
-	return queue_delayed_work_on(-1, wq, dwork, delay);
+	return queue_delayed_work_on(WORK_CPU_UNBOUND, wq, dwork, delay);
 }
 EXPORT_SYMBOL_GPL(queue_delayed_work);
 
@@ -2868,7 +2863,7 @@ bool flush_delayed_work(struct delayed_work *dwork)
 {
 	preempt_disable();
 	if (del_timer_sync(&dwork->timer))
-		__queue_work(raw_smp_processor_id(),
+		__queue_work(WORK_CPU_UNBOUND,
 			     get_work_cwq(&dwork->work)->wq, &dwork->work);
 	preempt_enable();
 	return flush_work(&dwork->work);
@@ -2891,7 +2886,7 @@ bool flush_delayed_work_sync(struct delayed_work *dwork)
 {
 	preempt_disable();
 	if (del_timer_sync(&dwork->timer))
-		__queue_work(raw_smp_processor_id(),
+		__queue_work(WORK_CPU_UNBOUND,
 			     get_work_cwq(&dwork->work)->wq, &dwork->work);
 	preempt_enable();
 	return flush_work_sync(&dwork->work);
-- 
1.7.7.3

