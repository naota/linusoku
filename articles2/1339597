Path: news.gmane.org!not-for-mail
From: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Newsgroups: gmane.linux.kernel,gmane.linux.kernel.stable
Subject: [ 078/109] netem: add limitation to reordered packets
Date: Tue,  7 Aug 2012 15:35:37 -0700
Lines: 121
Approved: news@gmane.org
Message-ID: <20120807222049.950071291@linuxfoundation.org>
References: <20120807222043.089735600@linuxfoundation.org>
NNTP-Posting-Host: plane.gmane.org
X-Trace: dough.gmane.org 1344380677 29078 80.91.229.3 (7 Aug 2012 23:04:37 GMT)
X-Complaints-To: usenet@dough.gmane.org
NNTP-Posting-Date: Tue, 7 Aug 2012 23:04:37 +0000 (UTC)
Cc: Greg KH <gregkh@linuxfoundation.org>,
	torvalds@linux-foundation.org, akpm@linux-foundation.org,
	alan@lxorguk.ukuu.org.uk, Eric Dumazet <edumazet@google.com>,
	Mark Gordon <msg@google.com>,
	Andreas Terzis <aterzis@google.com>,
	Yuchung Cheng <ycheng@google.com>,
	Hagen Paul Pfeifer <hagen@jauu.net>,
	"David S. Miller" <davem@davemloft.net>
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org
Original-X-From: linux-kernel-owner@vger.kernel.org Wed Aug 08 01:04:35 2012
Return-path: <linux-kernel-owner@vger.kernel.org>
Envelope-to: glk-linux-kernel-3@plane.gmane.org
Original-Received: from vger.kernel.org ([209.132.180.67])
	by plane.gmane.org with esmtp (Exim 4.69)
	(envelope-from <linux-kernel-owner@vger.kernel.org>)
	id 1SyspC-0008LK-P1
	for glk-linux-kernel-3@plane.gmane.org; Wed, 08 Aug 2012 01:04:31 +0200
Original-Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1030715Ab2HGXEW (ORCPT <rfc822;glk-linux-kernel-3@m.gmane.org>);
	Tue, 7 Aug 2012 19:04:22 -0400
Original-Received: from mail-pb0-f46.google.com ([209.85.160.46]:41610 "EHLO
	mail-pb0-f46.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1030706Ab2HGWkQ (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Tue, 7 Aug 2012 18:40:16 -0400
Original-Received: by mail-pb0-f46.google.com with SMTP id rr13so358014pbb.19
        for <linux-kernel@vger.kernel.org>; Tue, 07 Aug 2012 15:40:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20120113;
        h=from:to:cc:subject:date:message-id:x-mailer:in-reply-to:references
         :user-agent:x-gm-message-state;
        bh=gNSKJ4Xr0lZaBP87yNUQZZc1RpH56x1gLGZbyDX5Mh0=;
        b=BNb+/AH/vSwOBwcEFNMMo9zYUW5E4g1ocdTBT5VCBVZvcnqA6Z+XJIPzUcX9efg+Rd
         M/ZacXduXp5LaiGNtUzVMyCoLW5T8LbHFlGmvfPZ1I9UFN03IDB+Q3vyZygNY0mSE94L
         JHDxEdWXqhTBd0D/nBn9cvAhohxhp9lrchbcnPn4f+tIgefZ3r34vfL4kLAjmiPcT7WN
         f/ZFNyjaTCpFE8COiGj5goIPyCZThhgolpybov8lsgGZuPv1NZR2fXq67BTsOSy/XtkF
         9VkS0IPeixo2chjkMtyB6O9J7ecSAZ0nIeCBjiqf0w1FfeNZo4fc0nMg0bbqajHmTqVQ
         hlLQ==
Original-Received: by 10.68.201.195 with SMTP id kc3mr31576568pbc.33.1344379215520;
        Tue, 07 Aug 2012 15:40:15 -0700 (PDT)
Original-Received: from localhost (c-67-168-183-230.hsd1.wa.comcast.net. [67.168.183.230])
        by mx.google.com with ESMTPS id ro7sm6890275pbc.8.2012.08.07.15.40.13
        (version=TLSv1/SSLv3 cipher=OTHER);
        Tue, 07 Aug 2012 15:40:14 -0700 (PDT)
X-Mailer: git-send-email 1.7.10.1.362.g242cab3
In-Reply-To: <20120807222043.089735600@linuxfoundation.org>
User-Agent: quilt/0.60-20.4
X-Gm-Message-State: ALoCoQl76wRTMbGZuagC8OXD+CIA8L0GRbHiExPxlIHSa0xWZfs1Chd8Pvfxv21OqTh2ApfBupcJ
Original-Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: <linux-kernel.vger.kernel.org>
X-Mailing-List: linux-kernel@vger.kernel.org
Xref: news.gmane.org gmane.linux.kernel:1339597 gmane.linux.kernel.stable:29430
Archived-At: <http://permalink.gmane.org/gmane.linux.kernel/1339597>

From: Greg KH <gregkh@linuxfoundation.org>

3.4-stable review patch.  If anyone has any objections, please let me know.

------------------


From: Eric Dumazet <edumazet@google.com>

[ Upstream commit 960fb66e520a405dde39ff883f17ff2669c13d85 ]

Fix two netem bugs :

1) When a frame was dropped by tfifo_enqueue(), drop counter
   was incremented twice.

2) When reordering is triggered, we enqueue a packet without
   checking queue limit. This can OOM pretty fast when this
   is repeated enough, since skbs are orphaned, no socket limit
   can help in this situation.

Signed-off-by: Eric Dumazet <edumazet@google.com>
Cc: Mark Gordon <msg@google.com>
Cc: Andreas Terzis <aterzis@google.com>
Cc: Yuchung Cheng <ycheng@google.com>
Cc: Hagen Paul Pfeifer <hagen@jauu.net>
Signed-off-by: David S. Miller <davem@davemloft.net>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
---
 net/sched/sch_netem.c |   42 +++++++++++++++---------------------------
 1 file changed, 15 insertions(+), 27 deletions(-)

--- a/net/sched/sch_netem.c
+++ b/net/sched/sch_netem.c
@@ -329,29 +329,22 @@ static psched_time_t packet_len_2_sched_
 	return PSCHED_NS2TICKS(ticks);
 }
 
-static int tfifo_enqueue(struct sk_buff *nskb, struct Qdisc *sch)
+static void tfifo_enqueue(struct sk_buff *nskb, struct Qdisc *sch)
 {
 	struct sk_buff_head *list = &sch->q;
 	psched_time_t tnext = netem_skb_cb(nskb)->time_to_send;
-	struct sk_buff *skb;
+	struct sk_buff *skb = skb_peek_tail(list);
 
-	if (likely(skb_queue_len(list) < sch->limit)) {
-		skb = skb_peek_tail(list);
-		/* Optimize for add at tail */
-		if (likely(!skb || tnext >= netem_skb_cb(skb)->time_to_send))
-			return qdisc_enqueue_tail(nskb, sch);
-
-		skb_queue_reverse_walk(list, skb) {
-			if (tnext >= netem_skb_cb(skb)->time_to_send)
-				break;
-		}
+	/* Optimize for add at tail */
+	if (likely(!skb || tnext >= netem_skb_cb(skb)->time_to_send))
+		return __skb_queue_tail(list, nskb);
 
-		__skb_queue_after(list, skb, nskb);
-		sch->qstats.backlog += qdisc_pkt_len(nskb);
-		return NET_XMIT_SUCCESS;
+	skb_queue_reverse_walk(list, skb) {
+		if (tnext >= netem_skb_cb(skb)->time_to_send)
+			break;
 	}
 
-	return qdisc_reshape_fail(nskb, sch);
+	__skb_queue_after(list, skb, nskb);
 }
 
 /*
@@ -366,7 +359,6 @@ static int netem_enqueue(struct sk_buff
 	/* We don't fill cb now as skb_unshare() may invalidate it */
 	struct netem_skb_cb *cb;
 	struct sk_buff *skb2;
-	int ret;
 	int count = 1;
 
 	/* Random duplication */
@@ -414,6 +406,11 @@ static int netem_enqueue(struct sk_buff
 		skb->data[net_random() % skb_headlen(skb)] ^= 1<<(net_random() % 8);
 	}
 
+	if (unlikely(skb_queue_len(&sch->q) >= sch->limit))
+		return qdisc_reshape_fail(skb, sch);
+
+	sch->qstats.backlog += qdisc_pkt_len(skb);
+
 	cb = netem_skb_cb(skb);
 	if (q->gap == 0 ||		/* not doing reordering */
 	    q->counter < q->gap - 1 ||	/* inside last reordering gap */
@@ -445,7 +442,7 @@ static int netem_enqueue(struct sk_buff
 
 		cb->time_to_send = now + delay;
 		++q->counter;
-		ret = tfifo_enqueue(skb, sch);
+		tfifo_enqueue(skb, sch);
 	} else {
 		/*
 		 * Do re-ordering by putting one out of N packets at the front
@@ -455,16 +452,7 @@ static int netem_enqueue(struct sk_buff
 		q->counter = 0;
 
 		__skb_queue_head(&sch->q, skb);
-		sch->qstats.backlog += qdisc_pkt_len(skb);
 		sch->qstats.requeues++;
-		ret = NET_XMIT_SUCCESS;
-	}
-
-	if (ret != NET_XMIT_SUCCESS) {
-		if (net_xmit_drop_count(ret)) {
-			sch->qstats.drops++;
-			return ret;
-		}
 	}
 
 	return NET_XMIT_SUCCESS;


